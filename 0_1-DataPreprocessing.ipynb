{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Taking .docx file and making them remotely useful",
   "id": "e59db2ab309aeb48"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# path where the transcripts are stored \n",
    "#   (make this prior to running script and add all .docx formatted \n",
    "#    transcripts there.)\n",
    "TRANSCRIPTS_PATH = 'data/transcripts'\n",
    "\n",
    "# path where the corrected .csv formatted data will reside\n",
    "CORRECTED_TRANSCRIPTS_PATH = 'data/data'\n",
    "if not os.path.exists(CORRECTED_TRANSCRIPTS_PATH):\n",
    "    os.mkdir(CORRECTED_TRANSCRIPTS_PATH)\n",
    "\n",
    "files = [os.path.join(TRANSCRIPTS_PATH, p) for p in os.listdir(TRANSCRIPTS_PATH) if (not p.startswith('._'))]"
   ],
   "id": "246c25048ec65b56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "dc6b598fd7e5e354"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from docx import Document"
   ],
   "id": "1d7123e0fe2e661b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def process_(doc):\n",
    "    line, document = {'speaker': '', 'text': ''}, []\n",
    "    for text in list(doc.paragraphs):\n",
    "        if text.text == '':\n",
    "            if line['speaker']:\n",
    "                document += [line]\n",
    "            line = {'speaker': '', 'text': ''}\n",
    "        else:\n",
    "            if ('R (' in text.text) or ('L (' in text.text):\n",
    "                split_text = text.text.split(':')\n",
    "                line['speaker'] = split_text[0].strip()\n",
    "                if len(split_text) > 1:\n",
    "                    if len(split_text[1]) > 2:\n",
    "                        line['text'] += split_text[1].strip()\n",
    "                \n",
    "            else:\n",
    "                line['text'] += text.text\n",
    "    \n",
    "    return document\n",
    "\n",
    "def process(doc):\n",
    "    line, document = {'speaker': '', 'text': ''}, []\n",
    "    for text in list(doc.paragraphs):\n",
    "        # if text.text == '':\n",
    "        #     if line['speaker']:\n",
    "        #         document += [line]\n",
    "        #     line = {'speaker': '', 'text': ''}\n",
    "        # else:\n",
    "        TEXT = text.text\n",
    "        if ('R (' in TEXT) or ('L (' in TEXT):\n",
    "            \n",
    "            if '\\n\\n' in TEXT:\n",
    "                TEXT = TEXT.split('\\n\\n')\n",
    "                document[-1]['text'] += TEXT[0]\n",
    "                TEXT = TEXT[1]\n",
    "                \n",
    "            TEXT = TEXT.replace('((', '(').replace('))', ')')\n",
    "            \n",
    "            if TEXT.endswith(':'):\n",
    "                TEXT = TEXT[:-1] + ')'\n",
    "            # push line to document\n",
    "            document += [line]\n",
    "            line= {'speaker': '', 'text': ''}\n",
    "            \n",
    "            # start new line\n",
    "            try:\n",
    "                line['speaker'] = re.findall(r'[A-Z]+ \\([A-Z]\\)', TEXT)[0] #split_text[0]\n",
    "            except Exception:\n",
    "                print(TEXT)\n",
    "            \n",
    "            split_text = TEXT.split(line['speaker'])\n",
    "            document[-1]['text'] += split_text[0]\n",
    "            \n",
    "            # if len(split_text) > 1:\n",
    "            #     if len(split_text[1]) > 2:\n",
    "            # line['text'] += re.sub(r'[A-Z]+ \\([A-Z]\\)', ' ', text.text).strip()\n",
    "            # line['text'] += split_text[-1].strip()\n",
    "            \n",
    "        else:\n",
    "            #TEXT = TEXT.strip(' :)')\n",
    "            line['text'] += TEXT\n",
    "    \n",
    "    return document"
   ],
   "id": "26d1f4597c2a5155",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "for file_number,file in enumerate(files):\n",
    "    \n",
    "    print('{}: {}/{}'.format(file.split('/')[-1], file_number+1, len(files)))\n",
    "    \n",
    "    doc = process(Document(file))\n",
    "    df = pd.DataFrame(doc)\n",
    "    df['file'] = file\n",
    "    df['line_no'] = df.index\n",
    "    df['timestamp'] = df['text'].apply(lambda x: re.findall(r'\\d+:\\d+', x))\n",
    "    df['timestamp'] = [x[0] if len(x) else None for x in df['timestamp'].values]\n",
    "    df = df.loc[~df['speaker'].isna()]\n",
    "    df = df.loc[~df['speaker'].isin(['', ' '])]\n",
    "    \n",
    "    df['text'] = df['text'].apply(lambda x: re.sub(r'\\d+:\\d+', '', x))\n",
    "    \n",
    "    # created aligned document\n",
    "    df[['speaker2', 'text2', 'timestamp2']] = None\n",
    "    \n",
    "    for i in tqdm(df.index):\n",
    "        indexes = df.loc[\n",
    "            ~df['speaker'].isin([df['speaker'].loc[i]])\n",
    "            & (df['line_no'] > i)\n",
    "        ].index\n",
    "        if len(indexes):\n",
    "            df['speaker2'].loc[i] = df['speaker'].loc[indexes[0]]\n",
    "            df['text2'].loc[i] = df['text'].loc[indexes[0]]\n",
    "            df['timestamp2'].loc[i] = df['timestamp'].loc[indexes[0]]\n",
    "    \n",
    "    print(len(df))\n",
    "    print(df['speaker'].unique(), df['speaker2'].unique())\n",
    "    print('=====][=====')\n",
    "    \n",
    "    df.to_csv(\n",
    "        os.path.join(\n",
    "            CORRECTED_TRANSCRIPTS_PATH,\n",
    "            file.split('/')[-1].replace('.docx', '.csv')\n",
    "        ),\n",
    "        index=False, \n",
    "        encoding='utf-8'\n",
    "    )\n",
    "    "
   ],
   "id": "26edd2502bbc7f7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head(n=20)",
   "id": "d621863e9a7e27dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['timestamp'].isna().mean()",
   "id": "1c02bbb44b6cb873",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "39879f7361c1ef2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
