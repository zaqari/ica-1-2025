{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63c6f26b4ad57447",
   "metadata": {},
   "source": [
    "# Merging Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb79c26abc66a74e",
   "metadata": {},
   "source": [
    "As you can see from the scripts included in this project, we ended up batching the comparisons between our keyword utterances ($k \\in K$) and our context utterances ($c \\in C$). Partially, this was to decrease the noise in the office where the tower is stored while running our tests.\n",
    "\n",
    "The following scripts are designed to stitch those pieces back together again, largely using the CEDA object/framework to do so."
   ]
  },
  {
   "cell_type": "code",
   "id": "d0956efba2d9a14b",
   "metadata": {},
   "source": [
    "from shared.CEDA import ceda_model\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "22b58f0c8f1c1b91",
   "metadata": {},
   "source": [
    "CKPT_PATH = 'data/ckpts'\n",
    "RAW_PATH = 'data/data'\n",
    "OUT_PATH = 'data/results'\n",
    "META_DATA_PATH = 'data/meta_data'\n",
    "OUT_NAME = 'ceda-results.csv'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "15eedd03133b6e92",
   "metadata": {},
   "source": [
    "df = []"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3bfa56f293eeab79",
   "metadata": {},
   "source": [
    "mod = ceda_model()\n",
    "\n",
    "files = [os.path.join(CKPT_PATH, f) for f in os.listdir(CKPT_PATH) if not f.startswith('._') and f.endswith('.pt')]\n",
    "for f in tqdm(files):\n",
    "    mod.load_from_checkpoint(f)\n",
    "    df += [mod.graph_df(residualize=False)]\n",
    "    df[-1]['dyad'] = df[-1]['file'].values[0].split('/')[-1].replace('.docx', '')\n",
    "    \n",
    "    # label transition number in conversation\n",
    "    df[-1]['transition'] = df[-1].index.values + 1\n",
    "    \n",
    "    # label speaker per conversation (for enumerated labeling/further anonymization)\n",
    "    df[-1]['speaker'] = df[-1]['dyad'] + '-' + df[-1]['speaker']\n",
    "    df[-1]['speaker2'] = df[-1]['dyad'] + '-' + df[-1]['speaker2']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7a3574b492327c1a",
   "metadata": {},
   "source": [
    "df = pd.concat(df, ignore_index=True)\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c7faad022b4dbd8a",
   "metadata": {},
   "source": [
    "Stupidly, I left out some crucial information for ascertaining whether $x$ and $y$ (i.e. $k$ and $c$) are in the same context. That missing info being the parent comments for $x$ and $y$. To get those, I'm addding in the following script."
   ]
  },
  {
   "cell_type": "code",
   "id": "1aab27c84c68787e",
   "metadata": {},
   "source": [
    "dfc = [pd.read_csv(os.path.join(META_DATA_PATH, f)) for f in os.listdir(META_DATA_PATH) if not f.startswith('._') and f.endswith('.csv')]\n",
    "dfc = pd.concat(dfc, ignore_index=True)\n",
    "dfc.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "and let's merge the data with the metadata.",
   "id": "8fd902db1980e3ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dfc['Dyads'] = dfc['Dyads'].astype(str)",
   "id": "f9e07d844c97be38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.merge(\n",
    "    left=df, left_on='dyad',\n",
    "    right=dfc, right_on='Dyads',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "del df['Dyads']"
   ],
   "id": "69522d5541079ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head()",
   "id": "189b26818b2a78ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a8f33437a0328b29",
   "metadata": {},
   "source": [
    "Let's also take a moment now and anonymize some of the data (and save our anonymization key locally)"
   ]
  },
  {
   "cell_type": "code",
   "id": "73dc0044a1e985f6",
   "metadata": {},
   "source": [
    "anonymize_columns = [['speaker', 'speaker2'], ['dyad']]\n",
    "for cols in anonymize_columns:\n",
    "    values = np.unique(df[cols].values)\n",
    "    values = np.random.choice(values, size=(len(values),), replace=False)\n",
    "    \n",
    "    conversion = {val:i+1 for i,val in enumerate(values)}\n",
    "    \n",
    "    # save conversion dictionary\n",
    "    f = open(\n",
    "        os.path.join(\n",
    "            OUT_PATH, \n",
    "            cols[0].replace('x_', '').replace('y_', '')+'.json'\n",
    "        ), \n",
    "        'w'\n",
    "    )\n",
    "    f.write(json.dumps(conversion,indent=4))\n",
    "    f.close()\n",
    "    \n",
    "    # anonymize the column\n",
    "    for col in cols:\n",
    "        print(col)\n",
    "        df[col] = [conversion[val] for val in tqdm(df[col].values)]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "90365ec1e3d989f6",
   "metadata": {},
   "source": [
    "Finishing this, let's save the data."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.shape",
   "id": "686336084fb3e06a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.to_csv(os.path.join(OUT_PATH, OUT_NAME), index=False, encoding='utf-8')",
   "id": "ace17b546b6890c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "db121aa11950f572"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
